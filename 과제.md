# Part 2-2: 생산최적화 (Vision AI) - 실습 과제

> **기반 실습**: Vision Transformer(ViT), ViT Transfer Learning, YOLOv8 Fine-tuning
> **목표**: 최신 딥러닝 비전 기술로 제조 생산성 극대화

---

## 📋 과제 목록

### 🌟 Level 1: 기초 (1-3번)

### 과제 1: Transformer 아키텍처 이해 및 ViT 구조 분석
**난이도**: ⭐
**예상 소요 시간**: 3-4시간
**목표**: Transformer와 ViT의 핵심 개념 이해

**과제 내용**:
- Transformer의 핵심 구성 요소 정리:
  - Self-Attention 메커니즘
  - Multi-Head Attention
  - Positional Encoding
  - Feed-Forward Network
- ViT(Vision Transformer) 구조 분석:
  - Patch Embedding 과정 시각화
  - Class Token의 역할
  - Attention Map 해석
- CNN vs ViT 비교 분석 (장단점, 적용 상황)
- 간단한 Self-Attention 구현 (NumPy 또는 PyTorch)

**제출물**:
- Jupyter Notebook
- ViT 구조 분석 보고서 (PDF, 3-4페이지, 다이어그램 포함)

**평가 기준**:
- [ ] Transformer 핵심 개념 정리 (25%)
- [ ] ViT 구조 분석 정확성 (30%)
- [ ] CNN vs ViT 비교 (20%)
- [ ] Self-Attention 구현 (15%)
- [ ] 시각화 품질 (10%)

---

### 과제 2: Pre-trained ViT 모델 탐색 및 특징 추출
**난이도**: ⭐⭐
**예상 소요 시간**: 4-5시간
**목표**: 사전학습 모델 활용 능력

**과제 내용**:
- Hugging Face에서 다양한 ViT 모델 탐색:
  - `google/vit-base-patch16-224`
  - `google/vit-large-patch16-224`
  - `facebook/deit-base-distilled-patch16-224`
- 각 모델의 사양 비교 (파라미터 수, 입력 크기, 성능)
- 제조 이미지에 대해 특징 벡터 추출
- t-SNE 또는 UMAP으로 특징 공간 시각화
- 모델 크기 vs 성능 Trade-off 분석
- 실시간 추론 속도 측정 (CPU, GPU)

**제출물**:
- Jupyter Notebook
- 모델 비교 분석 보고서 (PDF)

**평가 기준**:
- [ ] 3개 이상 모델 탐색 (25%)
- [ ] 특징 추출 정확성 (25%)
- [ ] 시각화 품질 (20%)
- [ ] Trade-off 분석 (20%)
- [ ] 추론 속도 측정 (10%)

---

### 과제 3: ViT Fine-tuning 기초 - 단순 분류 태스크
**난이도**: ⭐⭐
**예상 소요 시간**: 5-6시간
**목표**: 전이학습 기본 프로세스 숙달

**과제 내용**:
- 제조 불량 이미지 데이터셋으로 ViT Fine-tuning
- 분류 헤드만 학습 (Feature Extraction)
- 학습 곡선 시각화 (Loss, Accuracy)
- Early Stopping 및 Model Checkpoint 적용
- 최종 모델 평가 (Confusion Matrix, Classification Report)
- CNN 기반 모델(MobileNetV2)과 성능 비교
- Fine-tuning 전후 성능 차이 분석

**제출물**:
- Jupyter Notebook
- Fine-tuning 결과 보고서 (PDF, 3-4페이지)
- 학습된 모델 파일

**평가 기준**:
- [ ] Fine-tuning 정확한 구현 (30%)
- [ ] 학습 곡선 분석 (20%)
- [ ] 모델 평가 완성도 (25%)
- [ ] CNN 모델과 비교 (15%)
- [ ] 성능 차이 분석 (10%)

---

### 🔥 Level 2: 중급 (4-7번)

### 과제 4: ViT Full Fine-tuning 및 Learning Rate Scheduler
**난이도**: ⭐⭐⭐
**예상 소요 시간**: 6-8시간
**목표**: 고급 Fine-tuning 전략 습득

**과제 내용**:
- Full Fine-tuning 구현 (전체 레이어 학습)
- Layer-wise Learning Rate 적용:
  - Backbone: 낮은 LR (1e-5)
  - Classification Head: 높은 LR (1e-3)
- Learning Rate Scheduler 실험:
  - Step Decay
  - Cosine Annealing
  - Warmup + Cosine
- Gradient Accumulation 적용 (배치 크기 제약 해결)
- Mixed Precision Training (FP16) 적용 및 속도 개선 측정
- Feature Extraction vs Full Fine-tuning 성능 비교

**제출물**:
- Jupyter Notebook
- Fine-tuning 전략 비교 보고서 (PDF)

**평가 기준**:
- [ ] Full Fine-tuning 구현 (25%)
- [ ] Layer-wise LR 적용 (20%)
- [ ] Scheduler 실험 (20%)
- [ ] Mixed Precision 적용 (15%)
- [ ] 성능 비교 분석 (20%)

---

### 과제 5: Attention Visualization 및 모델 해석
**난이도**: ⭐⭐⭐
**예상 소요 시간**: 6-7시간
**목표**: ViT의 의사결정 과정 이해

**과제 내용**:
- Attention Map 추출 및 시각화:
  - 각 레이어별 Attention 패턴
  - 각 헤드별 Attention 다양성
  - Class Token의 Attention 분포
- Attention Rollout 구현 (레이어 간 Attention 누적)
- 올바른 예측 vs 잘못된 예측의 Attention 차이 분석
- 모델이 집중하는 이미지 영역 식별
- CNN의 Grad-CAM과 ViT의 Attention Map 비교
- 불량 검출에서 Attention의 유용성 평가

**제출물**:
- Jupyter Notebook
- Attention 분석 보고서 (PDF, 시각 자료 풍부하게)

**평가 기준**:
- [ ] Attention Map 추출 정확성 (25%)
- [ ] 레이어/헤드별 분석 (25%)
- [ ] Attention Rollout 구현 (20%)
- [ ] Grad-CAM과 비교 (15%)
- [ ] 실무 적용 평가 (15%)

---

### 과제 6: YOLOv8 Object Detection 기초
**난이도**: ⭐⭐⭐
**예상 소요 시간**: 7-8시간
**목표**: 객체 탐지 실무 능력

**과제 내용**:
- YOLOv8 설치 및 환경 설정
- Pre-trained YOLOv8 모델로 추론 실습:
  - 제조 현장 이미지에서 객체 탐지
  - Confidence Threshold 조정 실험
  - NMS(Non-Maximum Suppression) 이해
- 커스텀 데이터셋 준비:
  - 이미지 수집 (최소 100장)
  - YOLO 형식으로 어노테이션 (LabelImg 또는 Roboflow)
  - 데이터셋 분할 (Train/Val/Test)
  - YAML 설정 파일 작성
- 기본 성능 지표 이해 (mAP, Precision, Recall)

**제출물**:
- Jupyter Notebook
- 어노테이션된 데이터셋 (ZIP)
- YOLOv8 기초 실습 보고서 (PDF)

**평가 기준**:
- [ ] YOLOv8 추론 성공 (20%)
- [ ] Threshold/NMS 실험 (20%)
- [ ] 데이터셋 준비 완성도 (30%)
- [ ] YAML 설정 정확성 (15%)
- [ ] 성능 지표 이해 (15%)

---

### 과제 7: YOLOv8 Fine-tuning 및 성능 최적화
**난이도**: ⭐⭐⭐⭐
**예상 소요 시간**: 8-10시간
**목표**: 커스텀 객체 탐지 모델 구축

**과제 내용**:
- YOLOv8 모델 선택 (n/s/m/l/x 중 적절한 크기)
- Fine-tuning 실행:
  - 에포크 수, 배치 크기, 이미지 크기 조정
  - Data Augmentation 전략
  - Hyperparameter 튜닝 (LR, Momentum, Weight Decay)
- 학습 과정 모니터링 (TensorBoard 또는 WandB)
- 성능 평가:
  - mAP@0.5, mAP@0.5:0.95 계산
  - Precision-Recall Curve
  - Confusion Matrix
- 오탐지(False Positive) 및 미탐지(False Negative) 분석
- 추론 속도 최적화 (TensorRT, ONNX 변환)

**제출물**:
- Jupyter Notebook
- 학습된 YOLOv8 모델 파일
- 성능 최적화 보고서 (PDF, 5-6페이지)

**평가 기준**:
- [ ] Fine-tuning 성공 (25%)
- [ ] Hyperparameter 튜닝 (20%)
- [ ] 성능 평가 완성도 (25%)
- [ ] 오탐/미탐 분석 (15%)
- [ ] 추론 속도 최적화 (15%)

---

### 💎 Level 3: 고급 (8-10번)

### 과제 8: ViT + Object Detection - 2-Stage 파이프라인
**난이도**: ⭐⭐⭐⭐
**예상 소요 시간**: 10-12시간
**목표**: 다중 모델 통합 능력

**과제 내용**:
- Stage 1: YOLOv8로 관심 영역(ROI) 탐지
- Stage 2: ViT로 탐지된 영역 세밀 분류
- 2-Stage 파이프라인 구축:
  - YOLOv8 추론 → Crop → ViT 추론
  - 결과 통합 (Bounding Box + 세부 클래스)
- 성능 비교:
  - YOLO 단독 vs 2-Stage 파이프라인
  - 정확도, 추론 속도, 메모리 사용량
- 엣지 디바이스 배포 가능성 평가
- 실시간 처리 최적화 (병렬 처리, 배치 추론)

**제출물**:
- Jupyter Notebook
- 2-Stage 파이프라인 코드
- 성능 비교 보고서 (PDF)
- 시연 동영상

**평가 기준**:
- [ ] 파이프라인 정확한 구현 (30%)
- [ ] 성능 비교 분석 (25%)
- [ ] 최적화 전략 (20%)
- [ ] 엣지 배포 평가 (15%)
- [ ] 시연 품질 (10%)

---

### 과제 9: 실시간 비전 검사 시스템 (웹캠 기반)
**난이도**: ⭐⭐⭐⭐⭐
**예상 소요 시간**: 12-15시간
**목표**: 실시간 비전 AI 시스템 구축

**과제 내용**:
- 웹캠 또는 IP 카메라 연동
- 실시간 비디오 스트림 처리:
  - 프레임 캡처 및 전처리
  - YOLOv8로 실시간 객체 탐지
  - ViT로 실시간 분류
- Streamlit 또는 Flask로 웹 인터페이스:
  - 라이브 비디오 피드
  - 탐지 결과 오버레이
  - 통계 대시보드 (FPS, 탐지 개수, 불량률)
  - 알람 시스템 (불량 검출 시)
- 성능 최적화:
  - 프레임 스킵 (매 N번째 프레임만 처리)
  - 모델 경량화 (Pruning, Quantization)
  - GPU 가속 활용
- 결과 로깅 및 리포팅 (CSV, 이미지 저장)

**제출물**:
- 웹 애플리케이션 코드
- 사용자 매뉴얼 (README.md)
- 시연 동영상 (5-10분)
- 성능 벤치마크 보고서

**평가 기준**:
- [ ] 실시간 처리 성공 (30%)
- [ ] 웹 인터페이스 완성도 (20%)
- [ ] 성능 최적화 (20%)
- [ ] 알람 및 로깅 기능 (15%)
- [ ] 문서화 및 시연 (15%)

---

### 과제 10: 종합 프로젝트 - AI 기반 스마트 품질 검사 라인
**난이도**: ⭐⭐⭐⭐⭐
**예상 소요 시간**: 25-35시간
**목표**: 엔드-투-엔드 비전 AI 솔루션 개발

**과제 내용**:
- **문제 정의**: 특정 제조 공정 선정 (PCB, 용접, 조립 등)
- **데이터 수집 및 관리**:
  - 이미지 데이터 수집 전략
  - 어노테이션 파이프라인 (효율적인 라벨링)
  - 데이터 버전 관리 (DVC 또는 유사 도구)
- **멀티 태스크 모델**:
  - 객체 탐지 (YOLOv8)
  - 불량 분류 (ViT)
  - 이상 탐지 (Autoencoder)
  - 모델 앙상블 전략
- **실시간 시스템**:
  - 고속 카메라 연동 (30-60 FPS)
  - 실시간 추론 파이프라인
  - PLC 또는 로봇 제어 연동 (선택 사항)
  - 웹 대시보드 (실시간 모니터링)
- **MLOps 파이프라인**:
  - CI/CD 구축 (자동 학습, 테스트, 배포)
  - 모델 성능 모니터링
  - Data Drift 감지 및 재학습 트리거
  - A/B 테스팅 프레임워크
- **엣지 배포**:
  - NVIDIA Jetson 또는 Intel NUC 타겟
  - 모델 최적화 (TensorRT, OpenVINO)
  - 오프라인 동작 모드
- **비즈니스 가치**:
  - ROI 계산 (인건비 절감, 불량률 감소)
  - 처리량 증가 정량화
  - 페이백 기간 산정
- **문서화**:
  - 시스템 아키텍처 문서
  - 운영 매뉴얼
  - 트러블슈팅 가이드
  - API 문서

**제출물**:
- 전체 프로젝트 코드 (GitHub 저장소)
- 시스템 아키텍처 문서 (PDF)
- 기술 문서 (설치, 설정, 운영)
- ROI 분석 보고서
- 시연 동영상 (20-30분)
- 최종 발표 자료 (PPT, 30-40 슬라이드)
- (선택) 실제 하드웨어 프로토타입

**평가 기준**:
- [ ] 문제 정의 및 비즈니스 가치 (10%)
- [ ] 데이터 파이프라인 완성도 (10%)
- [ ] 멀티 태스크 모델 성능 (15%)
- [ ] 실시간 시스템 완성도 (15%)
- [ ] MLOps 구현 (15%)
- [ ] 엣지 배포 (10%)
- [ ] ROI 분석 (10%)
- [ ] 문서화 (10%)
- [ ] 시연 및 발표 (5%)

---

## 📌 제출 가이드

### 파일 명명 규칙
```
Part2-2_과제{번호}_{학번}_{이름}.{확장자}
예: Part2-2_과제01_20240001_박민수.ipynb
```

### 제출 기한
- Level 1 (1-3번): 1주차
- Level 2 (4-7번): 2-4주차
- Level 3 (8-10번): 5주차 이후

### 평가 방식
- **Pass 기준**: 각 과제 70점 이상
- **우수 기준**: 90점 이상
- **추가 점수**: 실시간 성능, 엣지 배포, 비즈니스 가치

---

## 💡 학습 팁

1. **ViT 이해가 핵심**: Attention이 무엇을 보는지 직관적으로 이해하기
2. **YOLOv8 공식 문서 필독**: Ultralytics 문서는 매우 잘 되어 있음
3. **실시간 성능 최적화**: FPS가 1이라도 높으면 경쟁력 있음
4. **엣지 배포 경험**: 취업 면접에서 강력한 차별화 포인트

**도움이 필요하면**: Hugging Face 예제 → Ultralytics Docs → GitHub Issues → 강사 질문

**성공의 비결**: GPU 없으면 Colab 활용, 작은 모델로 빠르게 실험 → 점진적 확장! 🚀
