{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ YOLOv8 Fine-tuning (Object Detection)\n",
    "\n",
    "> **í•™ìŠµ ëª©í‘œ**: YOLOv8ë¡œ ì œì¡° ë¶ˆëŸ‰ ê°ì²´ íƒì§€ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ í•™ìŠµ ë‚´ìš©\n",
    "\n",
    "1. âœ… YOLOv8 ì•„í‚¤í…ì²˜ ì´í•´ (Anchor-free detection)\n",
    "2. âœ… YOLO ë°ì´í„°ì…‹ í˜•ì‹ ë³€í™˜ (COCO â†’ YOLO)\n",
    "3. âœ… YOLOv8n ëª¨ë¸ Fine-tuning (50 epochs, GPU)\n",
    "4. âœ… mAP@50, mAP@50-95 í‰ê°€\n",
    "5. âœ… Bounding Box ì‹œê°í™” ë° ì˜ˆì¸¡\n",
    "6. âœ… NMS Threshold íŠœë‹\n",
    "7. âœ… FPS ë²¤ì¹˜ë§ˆí‚¹ (ì‹¤ì‹œê°„ ì¶”ë¡  ì„±ëŠ¥)\n",
    "\n",
    "**ì†Œìš” ì‹œê°„**: ì•½ 60ë¶„ (í•™ìŠµ ì‹œê°„ í¬í•¨)  \n",
    "**ë‚œì´ë„**: â­â­â­â­ (ê³ ê¸‰)  \n",
    "**ì‚¬ì „ ì§€ì‹**: Object Detection ê°œë…, YOLO ì•„í‚¤í…ì²˜\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Step 1: ë¼ì´ë¸ŒëŸ¬ë¦¬ Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv8 (Ultralytics)\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    import ultralytics\n",
    "    print(f\"âœ… Ultralytics ë²„ì „: {ultralytics.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"âŒ Ultralytics ì„¤ì¹˜ í•„ìš”: pip install ultralytics\")\n",
    "\n",
    "# ì´ë¯¸ì§€ ì²˜ë¦¬\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# ì‹œê°í™”\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ìœ í‹¸ë¦¬í‹°\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"\\nâœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‚ Step 2: YOLO ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "\n",
    "**YOLO Format**:\n",
    "```\n",
    "dataset/\n",
    "â”œâ”€â”€ images/\n",
    "â”‚   â”œâ”€â”€ train/\n",
    "â”‚   â””â”€â”€ val/\n",
    "â”œâ”€â”€ labels/\n",
    "â”‚   â”œâ”€â”€ train/\n",
    "â”‚   â””â”€â”€ val/\n",
    "â””â”€â”€ data.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •\n",
    "dataset_root = Path('../data/defect_detection')\n",
    "dataset_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# YOLO ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±\n",
    "for split in ['train', 'val', 'test']:\n",
    "    (dataset_root / 'images' / split).mkdir(exist_ok=True, parents=True)\n",
    "    (dataset_root / 'labels' / split).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"ğŸ“‚ ë°ì´í„°ì…‹ ë£¨íŠ¸: {dataset_root}\")\n",
    "print(f\"\\nğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°:\")\n",
    "for item in sorted(dataset_root.rglob('*')):\n",
    "    if item.is_dir():\n",
    "        depth = len(item.relative_to(dataset_root).parts)\n",
    "        print(f\"{'  ' * depth}â””â”€â”€ {item.name}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„± (ì‹¤ì œ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°)\n",
    "# ì‹¤ì œ ì‚¬ìš© ì‹œ Dataset_XrayInspection.zip ì••ì¶• í•´ì œ í•„ìš”\n",
    "\n",
    "def create_sample_yolo_dataset(dataset_root, num_images=50):\n",
    "    \"\"\"ìƒ˜í”Œ YOLO ë°ì´í„°ì…‹ ìƒì„±\"\"\"\n",
    "    print(\"ğŸ”„ ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    # í´ë˜ìŠ¤ ì •ì˜\n",
    "    classes = ['scratch', 'contamination', 'crack', 'normal']\n",
    "    \n",
    "    for split, count in [('train', 35), ('val', 10), ('test', 5)]:\n",
    "        for idx in range(count):\n",
    "            # ëœë¤ ì´ë¯¸ì§€ ìƒì„±\n",
    "            img = np.random.randint(0, 256, (640, 640, 3), dtype=np.uint8)\n",
    "            img_path = dataset_root / 'images' / split / f'img_{idx:04d}.jpg'\n",
    "            Image.fromarray(img).save(img_path)\n",
    "            \n",
    "            # ëœë¤ bounding box ìƒì„± (YOLO format: class x_center y_center width height)\n",
    "            num_boxes = np.random.randint(1, 4)\n",
    "            label_path = dataset_root / 'labels' / split / f'img_{idx:04d}.txt'\n",
    "            \n",
    "            with open(label_path, 'w') as f:\n",
    "                for _ in range(num_boxes):\n",
    "                    cls = np.random.randint(0, len(classes) - 1)  # ì œì™¸ normal\n",
    "                    x_center = np.random.uniform(0.2, 0.8)\n",
    "                    y_center = np.random.uniform(0.2, 0.8)\n",
    "                    width = np.random.uniform(0.1, 0.3)\n",
    "                    height = np.random.uniform(0.1, 0.3)\n",
    "                    f.write(f\"{cls} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "    \n",
    "    print(f\"âœ… ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ (ì´ {num_images}ê°œ ì´ë¯¸ì§€)\")\n",
    "    return classes\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "classes = create_sample_yolo_dataset(dataset_root)\n",
    "\n",
    "# ë°ì´í„°ì…‹ í†µê³„\n",
    "for split in ['train', 'val', 'test']:\n",
    "    img_count = len(list((dataset_root / 'images' / split).glob('*.jpg')))\n",
    "    label_count = len(list((dataset_root / 'labels' / split).glob('*.txt')))\n",
    "    print(f\"ğŸ“Š {split:5s}: {img_count}ê°œ ì´ë¯¸ì§€, {label_count}ê°œ ë¼ë²¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.yaml ìƒì„±\n",
    "data_yaml = {\n",
    "    'path': str(dataset_root.absolute()),\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'test': 'images/test',\n",
    "    'nc': len(classes) - 1,  # í´ë˜ìŠ¤ ìˆ˜ (normal ì œì™¸)\n",
    "    'names': classes[:-1]  # í´ë˜ìŠ¤ ì´ë¦„ (normal ì œì™¸)\n",
    "}\n",
    "\n",
    "yaml_path = dataset_root / 'data.yaml'\n",
    "with open(yaml_path, 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(data_yaml, f, allow_unicode=True, default_flow_style=False)\n",
    "\n",
    "print(f\"âœ… data.yaml ìƒì„±: {yaml_path}\")\n",
    "print(f\"\\nğŸ“„ data.yaml ë‚´ìš©:\")\n",
    "print(yaml.dump(data_yaml, allow_unicode=True, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– Step 3: YOLOv8 ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv8 ëª¨ë¸ ì„ íƒ (nano - ê°€ì¥ ë¹ ë¥´ê³  ì‘ìŒ)\n",
    "model_name = 'yolov8n.pt'  # n (nano), s (small), m (medium), l (large), x (xlarge)\n",
    "\n",
    "print(f\"ğŸ”„ YOLOv8 ëª¨ë¸ ë¡œë”©: {model_name}...\")\n",
    "\n",
    "try:\n",
    "    model = YOLO(model_name)\n",
    "    \n",
    "    print(f\"\\nâœ… YOLOv8 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "    print(f\"\\nğŸ“Š ëª¨ë¸ ì •ë³´:\")\n",
    "    print(f\"   - ëª¨ë¸ í¬ê¸°: {model_name}\")\n",
    "    print(f\"   - Task: {model.task}\")\n",
    "    \n",
    "    # ëª¨ë¸ ì•„í‚¤í…ì²˜ ìš”ì•½\n",
    "    model_info = model.info()\n",
    "    print(f\"\\nğŸ—ï¸ ì•„í‚¤í…ì²˜ ìš”ì•½:\")\n",
    "    print(f\"   - Layers: {model.model.model[-1].i if hasattr(model.model, 'model') else 'N/A'}\")\n",
    "    print(f\"   - Parameters: ~3.0M (YOLOv8n)\")\n",
    "    print(f\"   - GFLOPs: ~8.1\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"   ultralytics ì„¤ì¹˜: pip install ultralytics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 4: Fine-tuning\n",
    "\n",
    "**í•™ìŠµ ì„¤ì •**:\n",
    "- Epochs: 50\n",
    "- Image size: 640\n",
    "- Batch size: 16 (GPU) / 8 (CPU)\n",
    "- Optimizer: AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ì„¤ì •\n",
    "train_params = {\n",
    "    'data': str(yaml_path),\n",
    "    'epochs': 50,\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,\n",
    "    'device': 0,  # 0=GPU, 'cpu'=CPU\n",
    "    'project': '../outputs/yolov8',\n",
    "    'name': 'defect_detection',\n",
    "    'patience': 10,  # Early stopping\n",
    "    'save': True,\n",
    "    'save_period': 10,  # Save every 10 epochs\n",
    "    'cache': False,\n",
    "    'workers': 4,\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "print(\"ğŸ“ í•™ìŠµ ì„¤ì •:\")\n",
    "for key, value in train_params.items():\n",
    "    print(f\"   - {key}: {value}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ í•™ìŠµ ì˜ˆìƒ ì‹œê°„: ~15-30ë¶„ (GPU), ~60-90ë¶„ (CPU)\")\n",
    "print(f\"   ì‹¤ì œ ë°ì´í„° ì‚¬ìš© ì‹œ ë°ì´í„°ì…‹ í¬ê¸°ì— ë”°ë¼ ë³€ë™\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\n",
    "print(\"ğŸ”„ YOLOv8 Fine-tuning ì‹œì‘...\\n\")\n",
    "\n",
    "try:\n",
    "    # í•™ìŠµ ì‹¤í–‰\n",
    "    results = model.train(**train_params)\n",
    "    \n",
    "    print(\"\\nâœ… í•™ìŠµ ì™„ë£Œ!\")\n",
    "    print(f\"\\nğŸ“Š í•™ìŠµ ê²°ê³¼:\")\n",
    "    print(f\"   - Best epoch: {results.best_epoch if hasattr(results, 'best_epoch') else 'N/A'}\")\n",
    "    print(f\"   - ì €ì¥ ê²½ë¡œ: {train_params['project']}/{train_params['name']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ í•™ìŠµ ì¤‘ ì—ëŸ¬: {e}\")\n",
    "    print(\"   ìƒ˜í”Œ ë°ì´í„°ë¡œ ì¸í•œ ì—ëŸ¬ì¼ ìˆ˜ ìˆìŒ\")\n",
    "    print(\"   ì‹¤ì œ ë°ì´í„°ì…‹ìœ¼ë¡œ ì¬ì‹œë„ ê¶Œì¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 5: ëª¨ë¸ í‰ê°€ (mAP)\n",
    "\n",
    "**í‰ê°€ ì§€í‘œ**:\n",
    "- mAP@50: IoU threshold 0.5ì—ì„œì˜ í‰ê·  ì •ë°€ë„\n",
    "- mAP@50-95: IoU 0.5~0.95 ë²”ìœ„ì˜ í‰ê·  ì •ë°€ë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best ëª¨ë¸ ë¡œë“œ\n",
    "best_model_path = Path(train_params['project']) / train_params['name'] / 'weights' / 'best.pt'\n",
    "\n",
    "if best_model_path.exists():\n",
    "    print(f\"ğŸ”„ Best ëª¨ë¸ ë¡œë”©: {best_model_path}\")\n",
    "    best_model = YOLO(str(best_model_path))\n",
    "else:\n",
    "    print(\"âš ï¸ Best ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©\")\n",
    "    best_model = model\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„°ì…‹ í‰ê°€\n",
    "print(\"\\nğŸ”„ ëª¨ë¸ í‰ê°€ ì¤‘...\")\n",
    "\n",
    "try:\n",
    "    metrics = best_model.val(data=str(yaml_path), split='val', batch=16)\n",
    "    \n",
    "    print(\"\\nâœ… í‰ê°€ ì™„ë£Œ!\")\n",
    "    print(f\"\\nğŸ“Š ì„±ëŠ¥ ì§€í‘œ:\")\n",
    "    \n",
    "    # mAP ì¶œë ¥\n",
    "    if hasattr(metrics, 'box'):\n",
    "        print(f\"   - mAP@50: {metrics.box.map50:.4f}\")\n",
    "        print(f\"   - mAP@50-95: {metrics.box.map:.4f}\")\n",
    "        print(f\"   - Precision: {metrics.box.p:.4f}\")\n",
    "        print(f\"   - Recall: {metrics.box.r:.4f}\")\n",
    "        \n",
    "        # Per-class mAP\n",
    "        if hasattr(metrics.box, 'ap_class_index'):\n",
    "            print(f\"\\nğŸ“Š í´ë˜ìŠ¤ë³„ mAP@50:\")\n",
    "            for idx, cls_name in enumerate(classes[:-1]):\n",
    "                ap50 = metrics.box.ap50[idx] if idx < len(metrics.box.ap50) else 0\n",
    "                print(f\"   - {cls_name}: {ap50:.4f}\")\n",
    "    else:\n",
    "        print(\"   í‰ê°€ ì§€í‘œ ì¶”ì¶œ ì‹¤íŒ¨ (ìƒ˜í”Œ ë°ì´í„°)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ í‰ê°€ ì¤‘ ì—ëŸ¬: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ Step 6: Bounding Box ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ ì¶”ë¡ \n",
    "test_images = list((dataset_root / 'images' / 'val').glob('*.jpg'))[:6]\n",
    "\n",
    "print(f\"ğŸ”„ ì¶”ë¡  ì‹¤í–‰ ì¤‘ ({len(test_images)}ê°œ ì´ë¯¸ì§€)...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    # ì¶”ë¡ \n",
    "    results = best_model(str(img_path), conf=0.25, iou=0.45, verbose=False)\n",
    "    \n",
    "    # ê²°ê³¼ ì´ë¯¸ì§€ (bounding box í¬í•¨)\n",
    "    result_img = results[0].plot()\n",
    "    result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    axes[idx].imshow(result_img)\n",
    "    \n",
    "    # Detection ê°œìˆ˜\n",
    "    num_detections = len(results[0].boxes)\n",
    "    axes[idx].set_title(f'{img_path.stem}\\nê²€ì¶œ: {num_detections}ê°œ', fontsize=10)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('YOLOv8 Detection ê²°ê³¼', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… ì¶”ë¡  ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›ï¸ Step 7: NMS Threshold íŠœë‹\n",
    "\n",
    "**NMS (Non-Maximum Suppression)**: ì¤‘ë³µ ë°•ìŠ¤ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ì–‘í•œ NMS threshold í…ŒìŠ¤íŠ¸\n",
    "nms_thresholds = [0.3, 0.45, 0.6, 0.75]\n",
    "conf_threshold = 0.25\n",
    "\n",
    "test_img = test_images[0]\n",
    "\n",
    "print(f\"ğŸ”„ NMS Threshold íŠœë‹ (confidence={conf_threshold})\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for idx, iou_thresh in enumerate(nms_thresholds):\n",
    "    # ì¶”ë¡ \n",
    "    results = best_model(str(test_img), conf=conf_threshold, iou=iou_thresh, verbose=False)\n",
    "    \n",
    "    # ê²°ê³¼ ì´ë¯¸ì§€\n",
    "    result_img = results[0].plot()\n",
    "    result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # í†µê³„\n",
    "    num_boxes = len(results[0].boxes)\n",
    "    avg_conf = results[0].boxes.conf.mean().item() if num_boxes > 0 else 0\n",
    "    \n",
    "    results_summary.append({\n",
    "        'iou_threshold': iou_thresh,\n",
    "        'num_boxes': num_boxes,\n",
    "        'avg_confidence': avg_conf\n",
    "    })\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    axes[idx].imshow(result_img)\n",
    "    axes[idx].set_title(f'IoU={iou_thresh}\\nBoxes: {num_boxes}, Avg Conf: {avg_conf:.3f}', fontsize=10)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('NMS Threshold ë¹„êµ', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ê²°ê³¼ ìš”ì•½\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(\"\\nğŸ“Š NMS Threshold ë¹„êµ ê²°ê³¼:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nğŸ’¡ ê¶Œì¥ ì„¤ì •:\")\n",
    "print(\"   - IoU 0.45: ì¼ë°˜ì ì¸ ê²½ìš° (default)\")\n",
    "print(\"   - IoU 0.3: ê²¹ì¹˜ëŠ” ê°ì²´ê°€ ë§ì€ ê²½ìš°\")\n",
    "print(\"   - IoU 0.6: ì¤‘ë³µ ì œê±°ë¥¼ ê°•í•˜ê²Œ ì ìš©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ Step 8: FPS ë²¤ì¹˜ë§ˆí‚¹\n",
    "\n",
    "ì‹¤ì‹œê°„ ì¶”ë¡  ì„±ëŠ¥ ì¸¡ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPS ë²¤ì¹˜ë§ˆí‚¹\n",
    "print(\"âš¡ FPS ë²¤ì¹˜ë§ˆí‚¹ ì‹¤í–‰ ì¤‘...\\n\")\n",
    "\n",
    "# ë‹¤ì–‘í•œ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë²¤ì¹˜ë§ˆí‚¹\n",
    "image_sizes = [320, 640, 1280]\n",
    "benchmark_results = []\n",
    "\n",
    "for imgsz in image_sizes:\n",
    "    print(f\"ğŸ”„ Image size: {imgsz}Ã—{imgsz}\")\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(10):\n",
    "        _ = best_model(str(test_images[0]), imgsz=imgsz, verbose=False)\n",
    "    \n",
    "    # ì‹¤ì œ ì¸¡ì •\n",
    "    start_time = time.time()\n",
    "    num_iterations = 100\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        _ = best_model(str(test_images[0]), imgsz=imgsz, verbose=False)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    fps = num_iterations / elapsed_time\n",
    "    latency = (elapsed_time / num_iterations) * 1000  # ms\n",
    "    \n",
    "    benchmark_results.append({\n",
    "        'image_size': imgsz,\n",
    "        'fps': fps,\n",
    "        'latency_ms': latency\n",
    "    })\n",
    "    \n",
    "    print(f\"   - FPS: {fps:.2f}\")\n",
    "    print(f\"   - Latency: {latency:.2f}ms\\n\")\n",
    "\n",
    "# ê²°ê³¼ ì‹œê°í™”\n",
    "benchmark_df = pd.DataFrame(benchmark_results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# FPS\n",
    "axes[0].bar(benchmark_df['image_size'].astype(str), benchmark_df['fps'], color='skyblue')\n",
    "axes[0].set_title('FPS by Image Size', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Image Size')\n",
    "axes[0].set_ylabel('FPS')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Latency\n",
    "axes[1].bar(benchmark_df['image_size'].astype(str), benchmark_df['latency_ms'], color='coral')\n",
    "axes[1].set_title('Inference Latency', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Image Size')\n",
    "axes[1].set_ylabel('Latency (ms)')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ ì—¬ë¶€\n",
    "realtime_fps = 30\n",
    "realtime_capable = benchmark_df[benchmark_df['fps'] >= realtime_fps]\n",
    "\n",
    "print(\"\\nğŸ“Š ë²¤ì¹˜ë§ˆí‚¹ ê²°ê³¼:\")\n",
    "print(benchmark_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nğŸ’¡ ì‹¤ì‹œê°„ ì²˜ë¦¬ (â‰¥{realtime_fps} FPS):\")\n",
    "if len(realtime_capable) > 0:\n",
    "    for _, row in realtime_capable.iterrows():\n",
    "        print(f\"   âœ… {row['image_size']}Ã—{row['image_size']}: {row['fps']:.1f} FPS\")\n",
    "else:\n",
    "    print(\"   âš ï¸ GPU ê°€ì† í•„ìš” ë˜ëŠ” ëª¨ë¸ ê²½ëŸ‰í™” ê¶Œì¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Step 9: ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "output_dir = Path('../outputs')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# í‰ê°€ ì§€í‘œ ì €ì¥\n",
    "if hasattr(metrics, 'box'):\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'metric': ['mAP@50', 'mAP@50-95', 'Precision', 'Recall'],\n",
    "        'value': [\n",
    "            metrics.box.map50,\n",
    "            metrics.box.map,\n",
    "            metrics.box.p,\n",
    "            metrics.box.r\n",
    "        ]\n",
    "    })\n",
    "    metrics_file = output_dir / '03_yolo_metrics.csv'\n",
    "    metrics_df.to_csv(metrics_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"âœ… í‰ê°€ ì§€í‘œ ì €ì¥: {metrics_file}\")\n",
    "\n",
    "# NMS threshold ê²°ê³¼ ì €ì¥\n",
    "nms_file = output_dir / '03_yolo_nms_comparison.csv'\n",
    "results_df.to_csv(nms_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"âœ… NMS ë¹„êµ ì €ì¥: {nms_file}\")\n",
    "\n",
    "# ë²¤ì¹˜ë§ˆí‚¹ ê²°ê³¼ ì €ì¥\n",
    "benchmark_file = output_dir / '03_yolo_fps_benchmark.csv'\n",
    "benchmark_df.to_csv(benchmark_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"âœ… FPS ë²¤ì¹˜ë§ˆí‚¹ ì €ì¥: {benchmark_file}\")\n",
    "\n",
    "print(\"\\nğŸ‰ YOLOv8 Fine-tuning ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "### âœ… ì™„ë£Œí•œ ë‚´ìš©\n",
    "1. YOLOv8 ì•„í‚¤í…ì²˜ ì´í•´ ë° ëª¨ë¸ ë¡œë“œ\n",
    "2. YOLO ë°ì´í„°ì…‹ í˜•ì‹ ë³€í™˜ (COCO â†’ YOLO txt)\n",
    "3. YOLOv8n Fine-tuning (50 epochs, GPU ê°€ì†)\n",
    "4. mAP@50, mAP@50-95 í‰ê°€ ì§€í‘œ ë¶„ì„\n",
    "5. Bounding Box ì‹œê°í™” ë° ì˜ˆì¸¡\n",
    "6. NMS Threshold íŠœë‹ (0.3, 0.45, 0.6, 0.75)\n",
    "7. FPS ë²¤ì¹˜ë§ˆí‚¹ (320, 640, 1280 ì´ë¯¸ì§€ í¬ê¸°)\n",
    "\n",
    "### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸\n",
    "\n",
    "- **YOLOv8 vs YOLOv5**:\n",
    "  - Anchor-free detection (ë” ê°„ë‹¨í•˜ê³  ë¹ ë¦„)\n",
    "  - Improved backbone (CSPDarknet â†’ C2f)\n",
    "  - Better accuracy-speed trade-off\n",
    "  - Ultralytics í†µí•© API (í›ˆë ¨/ì¶”ë¡ /ë°°í¬ ì¼ì›í™”)\n",
    "\n",
    "- **YOLO ë°ì´í„° í˜•ì‹**:\n",
    "  - ê° ì´ë¯¸ì§€ë§ˆë‹¤ txt íŒŒì¼ (class x_center y_center width height)\n",
    "  - ì¢Œí‘œëŠ” ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì •ê·œí™” (0~1 ë²”ìœ„)\n",
    "  - data.yamlë¡œ ë°ì´í„°ì…‹ êµ¬ì¡° ì •ì˜\n",
    "\n",
    "- **mAP ì´í•´**:\n",
    "  - mAP@50: IoU 0.5 ê¸°ì¤€ (ì¼ë°˜ì )\n",
    "  - mAP@50-95: COCO ë©”íŠ¸ë¦­ (ë” ì—„ê²©)\n",
    "  - Precision vs Recall trade-off ì´í•´ í•„ìš”\n",
    "\n",
    "- **NMS Tuning**:\n",
    "  - IoU ë‚®ì„ìˆ˜ë¡ ë” ë§ì€ ë°•ìŠ¤ ë³´ì¡´\n",
    "  - ê²¹ì¹˜ëŠ” ê°ì²´ê°€ ë§ìœ¼ë©´ IoU ë‚®ì¶¤ (0.3~0.4)\n",
    "  - ì¼ë°˜ì ìœ¼ë¡œ 0.45ê°€ ì ì ˆ\n",
    "\n",
    "- **ì‹¤ì‹œê°„ ì¶”ë¡ **:\n",
    "  - YOLOv8n: 640Ã—640ì—ì„œ ~100 FPS (GPU)\n",
    "  - 320Ã—320: ë‚®ì€ í•´ìƒë„, ë†’ì€ FPS\n",
    "  - 1280Ã—1280: ë†’ì€ ì •í™•ë„, ë‚®ì€ FPS\n",
    "  - ìš©ë„ì— ë”°ë¼ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •\n",
    "\n",
    "- **ì‹¤ë¬´ í™œìš©**:\n",
    "  - ì œì¡° ë¶ˆëŸ‰ ê²€ì¶œ: í‘œë©´ ê²°í•¨, ë¶€í’ˆ ëˆ„ë½\n",
    "  - ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì‚¬: ì»¨ë² ì´ì–´ ë²¨íŠ¸ ëª¨ë‹ˆí„°ë§\n",
    "  - ì•ˆì „ ê´€ë¦¬: ì‘ì—…ì ë³´í˜¸êµ¬ ì°©ìš© ê°ì§€\n",
    "  - ì¬ê³  ê´€ë¦¬: ìë™ ì¹´ìš´íŒ…, ìœ„ì¹˜ ì¶”ì \n",
    "\n",
    "### ğŸ“š ë‹¤ìŒ ë‹¨ê³„\n",
    "- **ëª¨ë¸ ê²½ëŸ‰í™”**: YOLOv8n â†’ TensorRT, ONNX ë³€í™˜\n",
    "- **ë°ì´í„° ì¦ê°•**: Mosaic, MixUp, Augmentation ê¸°ë²•\n",
    "- **ì•™ìƒë¸”**: ì—¬ëŸ¬ ëª¨ë¸ ê²°í•©ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ\n",
    "\n",
    "### ğŸ”— ì°¸ê³  ìë£Œ\n",
    "- [YOLOv8 ê³µì‹ ë¬¸ì„œ](https://docs.ultralytics.com/)\n",
    "- [Ultralytics GitHub](https://github.com/ultralytics/ultralytics)\n",
    "- [YOLO ë…¼ë¬¸ ì‹œë¦¬ì¦ˆ](https://arxiv.org/abs/2305.09972)\n",
    "\n",
    "---\n",
    "\n",
    "*ì œì¡°AI êµìœ¡ v12 Enhanced | Part 2-2 | 2025.02*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
