# Part 2-2: ìƒì‚°ìµœì í™” (Production Optimization)

> **v12 Enhanced**: ViT ì „ì´í•™ìŠµ + YOLOv8 ê°ì²´ íƒì§€ + ìµœì‹  ë¹„ì „ AI

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ

- âœ… Vision Transformer (ViT) ì´í•´
- âœ… ViT ì „ì´í•™ìŠµìœ¼ë¡œ ë¶ˆëŸ‰ ë¶„ë¥˜
- âœ… YOLOv8 Fine-tuning
- âœ… ì‹¤ì‹œê°„ ë¶ˆëŸ‰ íƒì§€ ì‹œìŠ¤í…œ
- âœ… ëª¨ë¸ ë°°í¬ ê¸°ì´ˆ

---

## ğŸ“š ì‹¤ìŠµ êµ¬ì„±

| ìˆœì„œ | ì‹¤ìŠµ | íŒŒì¼ | ì†Œìš” ì‹œê°„ | ë‚œì´ë„ |
|:----:|------|------|:---------:|:------:|
| 1 | ViT ê¸°ì´ˆ | `01_vit_introduction.ipynb` | 30ë¶„ | â­â­ |
| 2 | ViT ì „ì´í•™ìŠµ | `02_vit_transfer_learning.ipynb` | 60ë¶„ | â­â­â­ |
| 3 | YOLOv8 Fine-tuning | `03_yolov8_finetuning.ipynb` | 60ë¶„ | â­â­â­ |

**ì´ ì†Œìš” ì‹œê°„**: ì•½ 2.5ì‹œê°„

---

## ğŸš€ ì‹œì‘í•˜ê¸°

### 1ï¸âƒ£ í™˜ê²½ ì„¤ì •

```bash
# Part 2-2 í´ë”ë¡œ ì´ë™
cd practice-v12-enhanced/part2-2

# PyTorch ì„¤ì¹˜ (CUDA ì§€ì›)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# HuggingFace & Ultralytics
pip install transformers datasets accelerate ultralytics
```

### 2ï¸âƒ£ GPU í™•ì¸

```python
import torch
print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
print(f"GPU ì´ë¦„: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPUë§Œ ì‚¬ìš©'}")
```

---

## ğŸ“Š ì‚¬ìš© ëª¨ë¸

### Vision Transformer (ViT)

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ëª¨ë¸** | `google/vit-base-patch16-224` |
| **ìš©ë„** | ì´ë¯¸ì§€ ë¶„ë¥˜ |
| **íŒŒë¼ë¯¸í„°** | 86M |
| **ì…ë ¥ í¬ê¸°** | 224Ã—224 |

### YOLOv8

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ëª¨ë¸** | `yolov8n.pt` (nano) |
| **ìš©ë„** | ê°ì²´ íƒì§€ |
| **ì†ë„** | ~100 FPS (GPU) |
| **ì •í™•ë„** | mAP 37.3 |

---

## ğŸ”§ ì‹¤ìŠµ ìƒì„¸ ë‚´ìš©

### ì‹¤ìŠµ 1: ViT ê¸°ì´ˆ (30ë¶„)

**í•™ìŠµ ë‚´ìš©**:
- Transformer vs CNN ë¹„êµ
- ViT ì•„í‚¤í…ì²˜ ì´í•´
- ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë“œ
- ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë¶„ë¥˜

**ì£¼ìš” ì½”ë“œ**:
```python
from transformers import ViTImageProcessor, ViTForImageClassification
from PIL import Image
import torch

# ëª¨ë¸ & í”„ë¡œì„¸ì„œ ë¡œë“œ
processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')
model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')

# ì´ë¯¸ì§€ ë¶„ë¥˜
image = Image.open('defect.jpg')
inputs = processor(images=image, return_tensors="pt")
outputs = model(**inputs)
logits = outputs.logits

# ì˜ˆì¸¡
predicted_class = logits.argmax(-1).item()
print(f"ì˜ˆì¸¡ í´ë˜ìŠ¤: {model.config.id2label[predicted_class]}")
```

### ì‹¤ìŠµ 2: ViT ì „ì´í•™ìŠµ (60ë¶„)

**í•™ìŠµ ë‚´ìš©**:
- ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì¤€ë¹„
- ViT Fine-tuning
- í•™ìŠµ ëª¨ë‹ˆí„°ë§
- ì„±ëŠ¥ í‰ê°€ ë° ì‹œê°í™”

**ì£¼ìš” ì½”ë“œ**:
```python
from transformers import ViTForImageClassification, Trainer, TrainingArguments
from datasets import load_dataset

# ë°ì´í„°ì…‹ ë¡œë“œ
dataset = load_dataset("imagefolder", data_dir="./defect_images")

# ViT ëª¨ë¸ (í—¤ë“œ êµì²´)
model = ViTForImageClassification.from_pretrained(
    'google/vit-base-patch16-224',
    num_labels=4,  # ì–‘í’ˆ, ë¶ˆëŸ‰A, ë¶ˆëŸ‰B, ë¶ˆëŸ‰C
    ignore_mismatched_sizes=True
)

# í•™ìŠµ ì„¤ì •
training_args = TrainingArguments(
    output_dir="./vit_defect_model",
    per_device_train_batch_size=16,
    num_train_epochs=10,
    learning_rate=2e-4,
    logging_steps=50,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
)

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset['train'],
    eval_dataset=dataset['test'],
)

# í•™ìŠµ ì‹œì‘
trainer.train()
```

### ì‹¤ìŠµ 3: YOLOv8 Fine-tuning (60ë¶„)

**í•™ìŠµ ë‚´ìš©**:
- YOLO ë°ì´í„° í¬ë§· ì´í•´
- YOLOv8 ì»¤ìŠ¤í…€ í•™ìŠµ
- ì‹¤ì‹œê°„ ë¶ˆëŸ‰ íƒì§€
- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¶„ì„

**ì£¼ìš” ì½”ë“œ**:
```python
from ultralytics import YOLO

# YOLOv8 ëª¨ë¸ ë¡œë“œ
model = YOLO('yolov8n.pt')

# Fine-tuning
results = model.train(
    data='defect_dataset.yaml',  # ë°ì´í„°ì…‹ ì„¤ì •
    epochs=100,
    imgsz=640,
    batch=16,
    name='defect_detector',
    pretrained=True,
)

# ì¶”ë¡ 
results = model.predict(
    source='test_images/',
    conf=0.5,
    save=True,
    show_labels=True,
    show_conf=True,
)

# ê²€ì¦
metrics = model.val()
print(f"mAP50: {metrics.box.map50:.3f}")
print(f"mAP50-95: {metrics.box.map:.3f}")
```

---

## ğŸ’¡ í•™ìŠµ íŒ

### GPU ë©”ëª¨ë¦¬ ì ˆì•½

```python
# Mixed Precision Training
from transformers import TrainingArguments

training_args = TrainingArguments(
    fp16=True,  # 16-bit í•™ìŠµ
    gradient_accumulation_steps=2,  # Gradient ëˆ„ì 
    per_device_train_batch_size=8,  # Batch í¬ê¸° ì¡°ì •
)
```

### ë°ì´í„° ì¦ê°•

```python
from torchvision import transforms

transform = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ë…¼ë¬¸
- [An Image is Worth 16x16 Words (ViT)](https://arxiv.org/abs/2010.11929)
- [YOLOv8](https://docs.ultralytics.com/)

### ì½”ë“œ & ë¬¸ì„œ
- [HuggingFace Transformers](https://huggingface.co/docs/transformers)
- [Ultralytics YOLOv8](https://docs.ultralytics.com/models/yolov8/)

---

## ğŸ“ í•™ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ViT ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ì´í•´í–ˆë‹¤
- [ ] ViTë¡œ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì„ Fine-tuningí–ˆë‹¤
- [ ] YOLOv8ë¡œ ë¶ˆëŸ‰ íƒì§€ ëª¨ë¸ì„ í•™ìŠµí–ˆë‹¤
- [ ] ì‹¤ì‹œê°„ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³  ì„±ëŠ¥ì„ í‰ê°€í–ˆë‹¤

---

*ì œì¡°AI êµìœ¡ v12 Enhanced | Part 2-2 | 2025.02*
